### Gradient Descent: Algorithm to train a Neural Network

As you know, a Neural Network is a complex mathematical function with adjustable variables.
Gradient Descent is an optimization algorithm used to train a neural network by iteratively minimizing its loss function.

The algorithm works as follows:
“adjustable variable = weights”


1. Initialize weights randomly.
2. Loop until convergence.
3. Compute gradient, ∂J(W)/∂W
4. Update weight, W ← W -  η∂J(W)/∂W
5. Return weights.

<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/62cc2c9a-69bb-4b8f-84e3-39302cf3f4a3" />


